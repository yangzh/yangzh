{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0e1e7c8-0528-46b8-9398-58e566d33be0",
   "metadata": {},
   "source": [
    "This notebook illustrate how to connect to remote service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474dae7d-0b9e-47d7-b7eb-581846bef858",
   "metadata": {},
   "source": [
    "## `Aletheia` service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4862b0e8-7daf-4ae7-a40b-9d18ef736854",
   "metadata": {},
   "source": [
    "`aletheia` service provides nice interface to read/write memory systems composed of hyper-vectors.\n",
    "\n",
    "Currently it provides the following operations: \n",
    "\n",
    "* `Get`: get/retrieve chunks that meets certain criteria;\n",
    "\n",
    "* `Set`: set/write chunks with certain metadata;\n",
    "\n",
    "The chunks can be terminal, representing non-divisible concepts.\n",
    "In addition, we can produce composite chunk that are sequences of chunks (terminal or composite), set of chunks, etc.\n",
    "\n",
    "For example, if we model the English alphabet as terminal chunks, then each English word can be modelled as sequence of alphabets.\n",
    "\n",
    "NOTE this requires `alatheia` service, either running at local machine or an Internet-accessible IP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a01cff37-79e0-4797-a017-689044512a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "from kongming.util import remote_memory\n",
    "from kongming.data import lang\n",
    "\n",
    "from kongming.api import chunk_pb2, memory_pb2 \n",
    "\n",
    "with grpc.insecure_channel(target=\"localhost:8080\") as channel:\n",
    "    m = remote_memory.RemoteMemory(channel)\n",
    "    lang.populate_ascii(m)\n",
    "    lang.populate_words(m, \"lang:en\", [\n",
    "        \"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\",\n",
    "        \"world\", \"catherine\", \"university\", \"rate\", \"kitchen\",\n",
    "        \"something\", \"activity\", \"necessary\", \"other\", \"stuff\",\n",
    "        \"pattern\", \"director\", \"dying\", \"chinese\",\n",
    "        \"specialize\", \"some\", \"for\", \"cat\",\n",
    "        \"relax\", \"ing\", \"lifetime\",\n",
    "        \"uzbekistan\",\n",
    "        \"statistical\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b8b0f0-5b5a-4057-9108-1bd2418fdfbf",
   "metadata": {},
   "source": [
    "The script above connects to `aletheia` service, write English alphabets, followed by constructing some English words (as sequences of alphabets). \n",
    "Fuzzy query can be performed like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06c0a2b2-4bf4-47ed-986e-0b8d14d56c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[elemental {\n",
      "  hint: SPARSE_CONSTRAINED\n",
      "  model: MODEL_1M_10BIT\n",
      "  stable_hash: 4457954920353104723\n",
      "  sparse_constrained {\n",
      "    seed: 14336416972779868589\n",
      "  }\n",
      "}\n",
      "category: SEQUENCE\n",
      "refs {\n",
      "  namespace: \"lang:en\"\n",
      "  token: \"world\"\n",
      "}\n",
      "weight: 1024\n",
      ", elemental {\n",
      "  hint: SPARSE_CONSTRAINED\n",
      "  model: MODEL_1M_10BIT\n",
      "  stable_hash: 4334755355221515437\n",
      "  sparse_constrained {\n",
      "    seed: 13896323908361552193\n",
      "  }\n",
      "}\n",
      "category: SEQUENCE\n",
      "refs {\n",
      "  namespace: \"lang:en\"\n",
      "  token: \"for\"\n",
      "}\n",
      "weight: 148\n",
      ", elemental {\n",
      "  hint: SPARSE_CONSTRAINED\n",
      "  model: MODEL_1M_10BIT\n",
      "  stable_hash: 2914648003062445619\n",
      "  sparse_constrained {\n",
      "    seed: 3401615469385435847\n",
      "  }\n",
      "}\n",
      "category: SEQUENCE\n",
      "refs {\n",
      "  namespace: \"lang:en\"\n",
      "  token: \"fox\"\n",
      "}\n",
      "weight: 81\n",
      ", elemental {\n",
      "  hint: SPARSE_CONSTRAINED\n",
      "  model: MODEL_1M_10BIT\n",
      "  stable_hash: 5239658206539774533\n",
      "  sparse_constrained {\n",
      "    seed: 15671600646850579412\n",
      "  }\n",
      "}\n",
      "category: SEQUENCE\n",
      "refs {\n",
      "  namespace: \"lang:en\"\n",
      "  token: \"dog\"\n",
      "}\n",
      "weight: 68\n",
      ", elemental {\n",
      "  hint: SPARSE_CONSTRAINED\n",
      "  model: MODEL_1M_10BIT\n",
      "  stable_hash: 2258434123335087445\n",
      "  sparse_constrained {\n",
      "    seed: 17111227276508198549\n",
      "  }\n",
      "}\n",
      "category: SEQUENCE\n",
      "refs {\n",
      "  namespace: \"lang:en\"\n",
      "  token: \"some\"\n",
      "}\n",
      "weight: 46\n",
      ", elemental {\n",
      "  hint: SPARSE_CONSTRAINED\n",
      "  model: MODEL_1M_10BIT\n",
      "  stable_hash: 9175713737652511895\n",
      "  sparse_constrained {\n",
      "    seed: 1472203692898428992\n",
      "  }\n",
      "}\n",
      "category: SEQUENCE\n",
      "refs {\n",
      "  namespace: \"lang:en\"\n",
      "  token: \"director\"\n",
      "}\n",
      "weight: 29\n",
      ", elemental {\n",
      "  hint: SPARSE_CONSTRAINED\n",
      "  model: MODEL_1M_10BIT\n",
      "  stable_hash: 13499936636703739793\n",
      "  sparse_constrained {\n",
      "    seed: 1139225284434863374\n",
      "  }\n",
      "}\n",
      "category: SEQUENCE\n",
      "refs {\n",
      "  namespace: \"lang:en\"\n",
      "  token: \"something\"\n",
      "}\n",
      "weight: 24\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "with grpc.insecure_channel(target=\"localhost:8080\") as channel:\n",
    "    m = remote_memory.RemoteMemory(channel)\n",
    "    wordPicker = memory_pb2.ChunkPicker(\n",
    "            ref=chunk_pb2.ChunkReference(\n",
    "                namespace=\"lang:en\",\n",
    "                token=\"world\",\n",
    "            ))\n",
    "    got = m.Get(memory_pb2.ChunkPicker(near_neighbor=memory_pb2.NearNeighbor(target=wordPicker)))\n",
    "    print(got)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0c63c2-948f-4d93-a0ab-0a3081ecfe41",
   "metadata": {},
   "source": [
    "This result is worth careful examination and discussion.\n",
    "\n",
    "* First of all, the word `world` itself is returned (as full match, overlap=1024);\n",
    "* the word `for` is returned as second, with weight/overlap=148, since there are two letters overlap: `o` and `r`;\n",
    "* the word `fox` is returned, with weight/overlap=81, 1 letter overlapping: `o`;\n",
    "* the word `dog` is returned, with weight/overlap=68, 1 letter overlapping: `o`;\n",
    "* the word `some` is returned, with weight/overlap=46, 1 letter overlapping: `o`;\n",
    "* the word `director` is returned, with weight/overlap=29, 1 letter overlapping: `r`;\n",
    "* the word `something` is returned, with weight/overlap=24, 1 letter overlappng: `o`.\n",
    "\n",
    "All fuzzy matching is done at the server side, modelling cognitive similarity with the query word.\n",
    "Currently the matching can be achieved within a few milli-seconds.\n",
    "\n",
    "Similarly, spelling suggestions (for other words) also work perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260b1b4e-27d4-44d6-9fd4-58bf0139a73f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
